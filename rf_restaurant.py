# -*- coding: utf-8 -*-
"""RF_Restaurant.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1urjIi6TSoPWxGTY90qMFUTlvy_aEBoS0
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import LabelEncoder

#ignore warnings
import warnings
warnings.filterwarnings('ignore')

data = pd.read_csv('/content/restaurant_menu_optimization_data.csv')
print(data.head())

df=data.drop(columns=['RestaurantID'])
df

df.duplicated().sum()

df=df.drop_duplicates()

#encoding
le = LabelEncoder()

df['MenuCategory'] = le.fit_transform(df['MenuCategory'])
df['MenuItem'] = le.fit_transform(df['MenuItem'])
df['Ingredients'] = le.fit_transform(df['Ingredients'])
df['Profitability'] = le.fit_transform(df['Profitability'])

#split
#target column
target_column = 'Profitability'

X = df.drop(columns=[target_column]) # -> features all features without target
y = df[target_column]

from sklearn.model_selection import train_test_split

# Split data into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)

from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

# Initialize and train Random Forest model
random_forest = RandomForestClassifier()
random_forest.fit(X_train, y_train)

# Predict on test data
y_pred_random_forest = random_forest.predict(X_test)

# Evaluate Random Forest
print("Random Forest:")
print("Accuracy Score:", accuracy_score(y_test, y_pred_random_forest))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred_random_forest))
print("Classification Report:\n", classification_report(y_test, y_pred_random_forest))

actual_labels = y_test
predicted_labels = y_pred_random_forest

# Calculate counts of each label
actual_counts = pd.Series(actual_labels).value_counts().sort_index()
predicted_counts = pd.Series(predicted_labels).value_counts().sort_index()

# Create a DataFrame to align actual and predicted counts for plotting
comparison_df = pd.DataFrame({
    'Actual': actual_counts,
    'Predicted': predicted_counts
})

# Plotting
ax = comparison_df.plot(kind='bar', width=0.8, figsize=(10, 6))

# Customizing x-axis labels to match the actual label names
ax.set_xticklabels(['Low', 'Medium', 'High'])
plt.xlabel('Labels')
plt.ylabel('Count')
plt.title('Comparison of Actual and Predicted Labels')
plt.legend()
plt.show()

#Generate confusion matrix
confusion_matrix = confusion_matrix(y_test, y_pred_random_forest, labels=random_forest.classes_)

# Plotting the confusion matrix
plt.figure(figsize=(10, 7))
sns.heatmap(confusion_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=random_forest.classes_, yticklabels=random_forest.classes_)
plt.title('Confusion Matrix')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.show()